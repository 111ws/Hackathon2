////
////  CallView+BackendCommunication.swift
////  Hackathon2
////
////  Created by AI Assistant
////
//
//import SwiftUI
//import AVFoundation
//import Speech
//
//// MARK: - è°ƒè¯•åŠŸèƒ½æ‰©å±•
//extension CallView {
//    
//    /// æ·»åŠ è°ƒè¯•æ¶ˆæ¯
//    func addDebugMessage(_ message: String) {
//        let formatter = DateFormatter()
//        formatter.dateFormat = "HH:mm:ss.SSS"
//        let timestamp = formatter.string(from: Date())
//        let debugMessage = "[\(timestamp)] \(message)"
//        debugMessages.append(debugMessage)
//        print("ğŸ” \(debugMessage)")
//        
//        // é™åˆ¶è°ƒè¯•æ¶ˆæ¯æ•°é‡
//        if debugMessages.count > 50 {
//            debugMessages.removeFirst()
//        }
//    }
//    
//    /// è®¾ç½®éŸ³é¢‘ä¼šè¯
//    func setupAudioSession() {
//        let audioSession = AVAudioSession.sharedInstance()
//        do {
//            try audioSession.setCategory(.playAndRecord, mode: .voiceChat, options: [.allowBluetooth, .defaultToSpeaker, .duckOthers])
//            try audioSession.setActive(true)
//            addDebugMessage("Audio session configured successfully")
//        } catch {
//            addDebugMessage("Audio session configuration failed: \(error.localizedDescription)")
//        }
//    }
//}
//
//// MARK: - åç«¯é€šä¿¡æ‰©å±•
//extension CallView {
//    
//    /// å‘é€è¯­éŸ³æ–‡æœ¬åˆ°åç«¯
//    func sendSpeechToBackend(_ text: String) {
//        guard !text.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty else {
//            addDebugMessage("Skipping empty text")
//            return
//        }
//        
//        // é¿å…é‡å¤å‘é€ç›¸åŒå†…å®¹
//        if text == previousTranscription {
//            addDebugMessage("Skipping duplicate text: \(text)")
//            return
//        }
//        
//        previousTranscription = text
//        addDebugMessage("Preparing to send speech text: \(text)")
//        
//        let url = URL(string: "https://emohunter-biometric-api-6106408799.us-central1.run.app/api/v1/unified/emotion_chat")!
//        var request = URLRequest(url: url)
//        request.httpMethod = "POST"
//        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
//        
//        let requestBody: [String: Any] = [
//            "message": text,
//            "user_id": userId
//        ]
//        
//        do {
//            request.httpBody = try JSONSerialization.data(withJSONObject: requestBody)
//            addDebugMessage("Sending request to backend...")
//            
//            URLSession.shared.dataTask(with: request) { data, response, error in
//                DispatchQueue.main.async {
//                    if let error = error {
//                        self.addDebugMessage("Network request failed: \(error.localizedDescription)")
//                        return
//                    }
//                    
//                    guard let data = data else {
//                        self.addDebugMessage("No response data received")
//                        return
//                    }
//                    
//                    do {
//                        if let jsonResponse = try JSONSerialization.jsonObject(with: data) as? [String: Any] {
//                            self.addDebugMessage("Received backend response: \(jsonResponse)")
//                            
//                            if let audioUrl = jsonResponse["audio_url"] as? String {
//                                self.addDebugMessage("Starting audio download: \(audioUrl)")
//                                self.downloadAudioAndPlay(from: audioUrl)
//                            } else if let responseText = jsonResponse["response"] as? String {
//                                self.addDebugMessage("Received text response, requesting TTS: \(responseText)")
//                                self.requestTTSAudio(for: responseText)
//                            } else {
//                                self.addDebugMessage("No audio URL or text found in response")
//                            }
//                        }
//                    } catch {
//                        self.addDebugMessage("Response parsing failed: \(error.localizedDescription)")
//                    }
//                }
//            }.resume()
//            
//        } catch {
//            addDebugMessage("Request creation failed: \(error.localizedDescription)")
//        }
//    }
//    
//    /// è¯·æ±‚TTSéŸ³é¢‘
//    func requestTTSAudio(for text: String) {
//        let url = URL(string: "https://emohunter-biometric-api-6106408799.us-central1.run.app/api/v1/unified/tts")!
//        var request = URLRequest(url: url)
//        request.httpMethod = "POST"
//        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
//        
//        let requestBody: [String: Any] = [
//            "text": text,
//            "user_id": userId
//        ]
//        
//        do {
//            request.httpBody = try JSONSerialization.data(withJSONObject: requestBody)
//            addDebugMessage("Requesting TTS audio...")
//            
//            URLSession.shared.dataTask(with: request) { data, response, error in
//                DispatchQueue.main.async {
//                    if let error = error {
//                        self.addDebugMessage("TTS request failed: \(error.localizedDescription)")
//                        return
//                    }
//                    
//                    guard let data = data else {
//                        self.addDebugMessage("No TTS response data received")
//                        return
//                    }
//                    
//                    do {
//                        if let jsonResponse = try JSONSerialization.jsonObject(with: data) as? [String: Any],
//                           let audioUrl = jsonResponse["audio_url"] as? String {
//                            self.addDebugMessage("Received TTS audio URL: \(audioUrl)")
//                            self.downloadAudioAndPlay(from: audioUrl)
//                        } else {
//                            self.addDebugMessage("No audio URL found in TTS response")
//                        }
//                    } catch {
//                        self.addDebugMessage("TTS response parsing failed: \(error.localizedDescription)")
//                    }
//                }
//            }.resume()
//            
//        } catch {
//            addDebugMessage("TTS request creation failed: \(error.localizedDescription)")
//        }
//    }
//}
//
//// MARK: - éŸ³é¢‘å¤„ç†æ‰©å±•
//extension CallView {
//    
//    /// ä¸‹è½½å¹¶æ’­æ”¾éŸ³é¢‘
//    func downloadAudioAndPlay(from urlString: String) {
//        guard let url = URL(string: urlString) else {
//            addDebugMessage("Invalid audio URL: \(urlString)")
//            return
//        }
//        
//        addDebugMessage("Starting audio file download...")
//        audioDownloadProgress = 0.0
//        
//        URLSession.shared.dataTask(with: url) { data, response, error in
//            DispatchQueue.main.async {
//                if let error = error {
//                    self.addDebugMessage("Audio download failed: \(error.localizedDescription)")
//                    return
//                }
//                
//                guard let data = data else {
//                    self.addDebugMessage("Audio data is empty")
//                    return
//                }
//                
//                self.addDebugMessage("Audio download completed, starting playback")
//                self.audioDownloadProgress = 1.0
//                self.playAudioData(data)
//            }
//        }.resume()
//    }
//    
//    /// æ’­æ”¾éŸ³é¢‘æ•°æ®
//    func playAudioData(_ data: Data) {
//        do {
//            // åœæ­¢è¯­éŸ³è¯†åˆ«
//            stopSpeechRecognition()
//            
//            audioPlayer = try AVAudioPlayer(data: data)
//            audioPlayer?.delegate = CallViewAudioPlayerDelegate(callView: self)
//            
//            currentAudioDuration = audioPlayer?.duration ?? 0
//            audioPlaybackProgress = 0.0
//            isPlayingResponse = true
//            
//            audioPlayer?.play()
//            addDebugMessage("Started playing audio, duration: \(currentAudioDuration) seconds")
//            
//            startPlaybackProgressTimer()
//            
//        } catch {
//            addDebugMessage("Audio playback failed: \(error.localizedDescription)")
//            restartSpeechRecognition()
//        }
//    }
//    
//    /// å¼€å§‹æ’­æ”¾è¿›åº¦è®¡æ—¶å™¨
//    func startPlaybackProgressTimer() {
//        playbackTimer?.invalidate()
//        playbackTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
//            guard let player = self.audioPlayer, player.isPlaying else {
//                self.playbackTimer?.invalidate()
//                return
//            }
//            
//            self.audioPlaybackProgress = Float(player.currentTime / player.duration)
//        }
//    }
//    
//    /// åœæ­¢éŸ³é¢‘æ’­æ”¾
//    func stopAudioPlayback() {
//        audioPlayer?.stop()
//        audioPlayer = nil
//        playbackTimer?.invalidate()
//        isPlayingResponse = false
//        audioPlaybackProgress = 0.0
//        addDebugMessage("Audio playback stopped")
//    }
//}
//
//// MARK: - æ”¹è¿›çš„è¯­éŸ³è¯†åˆ«æ‰©å±•
//extension CallView {
//    
//    /// æ”¹è¿›çš„è¿ç»­è¯­éŸ³è¯†åˆ«æ–¹æ³•
//    func startImprovedSpeechRecognition() {
//        guard !isMuted,
//              speechRecognizer?.isAvailable == true,
//              SFSpeechRecognizer.authorizationStatus() == .authorized else {
//            addDebugMessage("Speech recognition conditions not met")
//            return
//        }
//        
//        // åœæ­¢ä¹‹å‰çš„ä»»åŠ¡
//        stopSpeechRecognition()
//        addDebugMessage("Starting improved speech recognition")
//        
//        // é…ç½®éŸ³é¢‘ä¼šè¯
//        setupAudioSession()
//        
//        // åˆ›å»ºè¯†åˆ«è¯·æ±‚
//        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
//        guard let recognitionRequest = recognitionRequest else {
//            addDebugMessage("Unable to create speech recognition request")
//            return
//        }
//        
//        recognitionRequest.shouldReportPartialResults = true
//        recognitionRequest.requiresOnDeviceRecognition = false
//        
//        // é…ç½®éŸ³é¢‘å¼•æ“
//        let inputNode = audioEngine.inputNode
//        let recordingFormat = inputNode.outputFormat(forBus: 0)
//        
//        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { buffer, _ in
//            recognitionRequest.append(buffer)
//        }
//        
//        audioEngine.prepare()
//        
//        do {
//            try audioEngine.start()
//            addDebugMessage("Audio engine started successfully")
//        } catch {
//            addDebugMessage("Audio engine startup failed: \(error.localizedDescription)")
//            return
//        }
//        
//        // å¼€å§‹è¯†åˆ«
//        recognitionTask = speechRecognizer?.recognitionTask(with: recognitionRequest) { result, error in
//            DispatchQueue.main.async {
//                if let result = result {
//                    let newText = result.bestTranscription.formattedString
//                    self.currentSpeechText = newText
//                    
//                    // æ£€æµ‹æ˜¯å¦åœ¨è¯´è¯
//                    self.isSpeaking = !newText.isEmpty
//                    
//                    // é‡ç½®å®šæ—¶å™¨
//                    self.speechTimer?.invalidate()
//                    self.speechTimer = Timer.scheduledTimer(withTimeInterval: 2.0, repeats: false) { _ in
//                        // 2ç§’æ²¡æœ‰æ–°çš„è¯­éŸ³è¾“å…¥ï¼Œå‘é€åˆ°åç«¯
//                        if !self.currentSpeechText.isEmpty {
//                            self.addDebugMessage("Speech recognition completed, sending to backend: \(self.currentSpeechText)")
//                            self.sendSpeechToBackend(self.currentSpeechText)
//                            self.speechHistory.append(self.currentSpeechText)
//                            self.currentSpeechText = ""
//                            self.isSpeaking = false
//                        }
//                    }
//                    
//                    if result.isFinal {
//                        // è¯†åˆ«å®Œæˆï¼Œç«‹å³å‘é€å¹¶é‡æ–°å¼€å§‹
//                        self.addDebugMessage("Final recognition result: \(newText)")
//                        self.sendSpeechToBackend(newText)
//                        self.speechHistory.append(newText)
//                        self.currentSpeechText = ""
//                        self.isSpeaking = false
//                        self.restartSpeechRecognition()
//                    }
//                }
//                
//                if let error = error {
//                    self.addDebugMessage("Speech recognition error: \(error.localizedDescription)")
//                    self.restartSpeechRecognition()
//                }
//            }
//        }
//    }
//}
//
//// MARK: - CallViewä¸“ç”¨éŸ³é¢‘æ’­æ”¾ä»£ç†
//class CallViewAudioPlayerDelegate: NSObject, AVAudioPlayerDelegate {
//    private var callView: CallView
//    
//    init(callView: CallView) {
//        self.callView = callView
//        super.init()
//    }
//    
//    func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
//        DispatchQueue.main.async {
//            self.callView.addDebugMessage("Audio playback completed")
//            self.callView.isPlayingResponse = false
//            self.callView.playbackTimer?.invalidate()
//            self.callView.restartSpeechRecognition()
//        }
//    }
//    
//}
