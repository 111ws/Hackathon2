import SwiftUI
import AVFoundation
import Speech

class StandaloneCallView: ObservableObject {
    var previousTranscription: String = ""
    @Published var isVideoEnabled = true
    @Published var isFrontCamera = true
    @Published var isCallActive = true
    @Published var callDuration: TimeInterval = 0
    @Published var currentSpeechText = ""
    @Published var speechHistory: [String] = []
    @Published var isSpeaking = false
    @Published var isMuted = false
    @Published var audioPlayer: AVAudioPlayer?
    @Published var isPlayingResponse = false
    @Published var debugMessages: [String] = []
    @Published var showDebugLog = false
    @Published var audioDownloadProgress: Float = 0.0
    @Published var currentAudioDuration: TimeInterval = 0
    @Published var audioPlaybackProgress: Float = 0.0
    
    var timer: Timer?
    var speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "en-US"))
    var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    var recognitionTask: SFSpeechRecognitionTask?
    var audioEngine = AVAudioEngine()
    var speechTimer: Timer?
    var playbackTimer: Timer?
    
    // Ê∑ªÂä†VADÁõ∏ÂÖ≥Â±ûÊÄß
    var isRecording = false
    var speechBuffer = Data()
    var silenceTimer: Timer?
    var lastSpeechTime: Date?
    var speechStartTime: Date?
    
    // VAD ÈÖçÁΩÆÂèÇÊï∞
    let silenceThreshold: Float = -40.0  // ÈùôÈü≥ÈòàÂÄº (dB)
    let silenceDuration: TimeInterval = 0.5  // ÈùôÈü≥ÊåÅÁª≠Êó∂Èó¥
    let minSpeechDuration: TimeInterval = 0.5  // ÊúÄÂ∞èËØ≠Èü≥ÊåÅÁª≠Êó∂Èó¥
    let maxSpeechDuration: TimeInterval = 10.0  // ÊúÄÂ§ßËØ≠Èü≥ÊåÅÁª≠Êó∂Èó¥
    
    let contactName = "Aura"
    let userId = "user_001"
    let speechSynthesizer = AVSpeechSynthesizer()
}

struct StandaloneCallViewWrapper: View {
    @StateObject   var viewModel = StandaloneCallView()
    
    var body: some View {
        StandaloneCallContent(viewModel: viewModel)
    }
}

struct StandaloneCallContent: View {
    @ObservedObject var viewModel: StandaloneCallView
    
    var body: some View {
        ZStack {
            if viewModel.isVideoEnabled {
                remoteView()
                    .ignoresSafeArea()
            } else {
                LinearGradient(
                    gradient: Gradient(colors: [
                        Color(red: 0.98, green: 0.75, blue: 0.65),
                        Color(red: 0.99, green: 0.85, blue: 0.55)
                    ]),
                    startPoint: .topLeading,
                    endPoint: .bottomTrailing
                )
                .ignoresSafeArea()
            }
            
            VStack(spacing: 40) {
                Spacer()
                
                if !viewModel.isVideoEnabled {
                    Circle()
                        .fill(Color.clear)
                        .frame(width: 150, height: 150)
                        .overlay(
                            AdvancedGradientRippleAnimation(
                                color: viewModel.isSpeaking ? .green : .white,
                                maxSize: viewModel.isSpeaking ? 200 : 180,
                                centerColor: viewModel.isSpeaking ? Color.green : Color.white,
                                edgeColor: .clear
                            )
                            .frame(width: 300, height: 300)
                            .animation(.easeInOut(duration: 0.3), value: viewModel.isSpeaking)
                        )
                }
                
                Text(viewModel.contactName)
                    .font(.largeTitle)
                    .fontWeight(.medium)
                    .foregroundColor(.white)
                    .shadow(color: .black.opacity(0.5), radius: 2)
                if viewModel.isPlayingResponse {
                    HStack {
                        Image(systemName: "speaker.wave.2.fill")
                            .foregroundColor(.blue)
                        Text("Playing response...")
                            .foregroundColor(.white)
                    }
                    .animation(.easeInOut, value: viewModel.isPlayingResponse)
                }
                
                Spacer()
                
                // ÈÄöËØùÊéßÂà∂ÊåâÈíÆ
                HStack(spacing: 40) {
                    // ËßÜÈ¢ëÂºÄÂÖ≥ÊåâÈíÆ
                    Button(action: {
                        viewModel.isVideoEnabled.toggle()
                    }) {
                        Circle()
                            .fill(viewModel.isVideoEnabled ? Color.blue : Color.gray.opacity(0.3))
                            .frame(width: 65, height: 65)
                            .overlay(
                                Image(systemName: viewModel.isVideoEnabled ? "video.fill" : "video.slash.fill")
                                    .font(.system(size: 24))
                                    .foregroundColor(.white)
                            )
                    }
                    
                    Button(action: {
                        // Êâ¨Â£∞Âô®ÂäüËÉΩÂÆûÁé∞
                    }) {
                        Circle()
                            .fill(Color.gray.opacity(0.3))
                            .frame(width: 65, height: 65)
                            .overlay(
                                Image(systemName: "speaker.wave.2.fill")
                                    .font(.system(size: 24))
                                    .foregroundColor(.white)
                            )
                    }

                    Button(action: {
                        viewModel.endCall()
                    }) {
                        Circle()
                            .fill(Color.red)
                            .frame(width: 70, height: 70)
                            .overlay(
                                Image(systemName: "phone.down.fill")
                                    .font(.system(size: 30))
                                    .foregroundColor(.white)
                            )
                    }
                }
                .padding(.bottom, 50)
            }
            .padding()
            // Êú¨Âú∞ËßÜÈ¢ëÈ¢ÑËßàÁ™óÂè£
            if viewModel.isVideoEnabled {
                HStack {
                    SimpleCameraView()
                        .frame(width: 120, height: 160)
                        .background(Color.black.opacity(0.1))
                        .cornerRadius(12)
                        .overlay(
                            RoundedRectangle(cornerRadius: 12)
                                .stroke(Color.white, lineWidth: 0.6)
                        )
                        .shadow(color: .black.opacity(0.5), radius: 10, x: 0, y: 5)
                        .padding(.horizontal, -190)
                        .padding(.top, -330)
                }
                .zIndex(1000)
            }
            
            // Ë∞ÉËØïÊó•Âøó
            if viewModel.showDebugLog {
                VStack {
                    Spacer()
                    ScrollView {
                        VStack(alignment: .leading) {
                            ForEach(viewModel.debugMessages, id: \.self) { message in
                                Text(message)
                                    .font(.system(size: 12))
                                    .foregroundColor(.white)
                                    .padding(.horizontal, 8)
                                    .padding(.vertical, 2)
                            }
                        }
                        .padding()
                        .background(Color.black.opacity(0.7))
                        .cornerRadius(12)
                    }
                    .frame(height: 200)
                    .padding()
                }
            }
            
            VStack {
                HStack {
                    Spacer()
                    Button(action: { viewModel.showDebugLog.toggle() }) {
                        Image(systemName: "ladybug.fill")
                            .foregroundColor(.yellow)
                            .padding()
                    }
                }
                Spacer()
            }
        }
        .onAppear {
            viewModel.startCallTimer()
            viewModel.requestSpeechAuthorization()
            viewModel.setupAudioSession()
            viewModel.addDebugMessage("App started, initializing audio session")
        }
        .onDisappear {
            viewModel.stopCallTimer()
            viewModel.stopSpeechRecognition()
            viewModel.stopAudioPlayback()
            viewModel.addDebugMessage("App closed, cleaning up resources")
        }
    }
    
      var statusText: String {
        if viewModel.isMuted {
            return "Muted - \(viewModel.timeString(from: viewModel.callDuration))"
        } else {
            return viewModel.timeString(from: viewModel.callDuration)
        }
    }
}

class AudioPlayerDelegate: NSObject, AVAudioPlayerDelegate {
    weak var parent: StandaloneCallView?
    
    init(parent: StandaloneCallView) {
        self.parent = parent
    }
    
    func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        DispatchQueue.main.async {
            self.parent?.addDebugMessage("üéµ Audio playback completed")
            self.parent?.isPlayingResponse = false
            self.parent?.stopPlaybackProgressTimer()
            self.parent?.restartSpeechRecognition()
        }
    }
    
    func audioPlayerDecodeErrorDidOccur(_ player: AVAudioPlayer, error: Error?) {
        DispatchQueue.main.async {
            self.parent?.addDebugMessage("‚ùå Audio decode error: \(error?.localizedDescription ?? "Unknown error")")
            self.parent?.isPlayingResponse = false
            self.parent?.restartSpeechRecognition()
        }
    }
}
#Preview {
    StandaloneCallViewWrapper()
}
