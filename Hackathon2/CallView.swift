//
//  CallView.swift
//  Hackathon2
//
//  Created by é™†æ°å¹²é¥­ç‹ on 03-08-2025.
//


import SwiftUI
import AVFoundation
import CallKit
import PushKit

// å½•éŸ³ç®¡ç†å™¨
class AudioRecordingManager: NSObject, ObservableObject {
    private var audioRecorder: AVAudioRecorder?
    private var recordingURL: URL?
    private var volumeTimer: Timer?
    private var silenceTimer: Timer?
    private var isMonitoring = false
    
    @Published var isRecording = false
    @Published var currentVolume: Float = 0.0
    
    // éŸ³é‡é˜ˆå€¼å’Œé™éŸ³æ£€æµ‹æ—¶é—´
    private let volumeThreshold: Float = 1// éŸ³é‡é˜ˆå€¼ï¼Œå¤§äºæ­¤å€¼è®¤ä¸ºåœ¨è¯´è¯
    private let silenceDetectionTime: TimeInterval = 3.0 // 3ç§’é™éŸ³ååœæ­¢å½•éŸ³
    
    override init() {
        super.init()
        print("[å½•éŸ³è°ƒè¯•] AudioRecordingManager åˆå§‹åŒ–")
        setupAudioSession()
    }
    
    private func setupAudioSession() {
        print("[å½•éŸ³è°ƒè¯•] å¼€å§‹è®¾ç½®éŸ³é¢‘ä¼šè¯")
        
        do {
            let audioSession = AVAudioSession.sharedInstance()
            try audioSession.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker, .allowBluetooth])
            try audioSession.setActive(true)
            print("[å½•éŸ³è°ƒè¯•] éŸ³é¢‘ä¼šè¯è®¾ç½®æˆåŠŸ")
            
            // è¯·æ±‚å½•éŸ³æƒé™
            audioSession.requestRecordPermission { granted in
                DispatchQueue.main.async {
                    print("[å½•éŸ³è°ƒè¯•] å½•éŸ³æƒé™è¯·æ±‚ç»“æœ: \(granted ? "å·²æˆæƒ" : "è¢«æ‹’ç»")")
                    if granted {
                        self.startVolumeMonitoring()
                    }
                }
            }
        } catch {
            print("[å½•éŸ³è°ƒè¯•] éŸ³é¢‘ä¼šè¯è®¾ç½®å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    // å¼€å§‹éŸ³é‡ç›‘æµ‹
    func startVolumeMonitoring() {
        guard !isMonitoring else { return }
        
        print("[å½•éŸ³è°ƒè¯•] å¼€å§‹éŸ³é‡ç›‘æµ‹")
        isMonitoring = true
        
        // åˆ›å»ºä¸€ä¸ªæŒç»­å½•éŸ³çš„å½•éŸ³å™¨ç”¨äºéŸ³é‡ç›‘æµ‹
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        let monitoringURL = documentsPath.appendingPathComponent("volume_monitor.m4a")
        
        let settings = [
            AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
            AVSampleRateKey: 44100,
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.medium.rawValue
        ]
        
        do {
            // ä½¿ç”¨ä¸€ä¸ªä¸“é—¨çš„ç›‘æµ‹å½•éŸ³å™¨
            let monitorRecorder = try AVAudioRecorder(url: monitoringURL, settings: settings)
            monitorRecorder.isMeteringEnabled = true
            monitorRecorder.prepareToRecord()
            
            // å¼€å§‹å½•éŸ³ä»¥ç›‘æµ‹éŸ³é‡
            if monitorRecorder.record() {
                print("[å½•éŸ³è°ƒè¯•] éŸ³é‡ç›‘æµ‹å½•éŸ³å™¨å¯åŠ¨æˆåŠŸ")
                
                // å®šæ—¶æ£€æµ‹éŸ³é‡
                volumeTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
                    monitorRecorder.updateMeters()
                    let averagePower = monitorRecorder.averagePower(forChannel: 0)
                    let peakPower = monitorRecorder.peakPower(forChannel: 0)
                    let volume = self.convertPowerToVolume(averagePower)
                    
                    print("[å½•éŸ³è°ƒè¯•] åŸå§‹åˆ†è´å€¼: \(averagePower), å³°å€¼: \(peakPower), è½¬æ¢åéŸ³é‡: \(volume)")
                    
                    DispatchQueue.main.async {
                        self.currentVolume = volume
                        self.handleVolumeChange(volume)
                    }
                }
            } else {
                print("[å½•éŸ³è°ƒè¯•] éŸ³é‡ç›‘æµ‹å½•éŸ³å™¨å¯åŠ¨å¤±è´¥")
            }
            
        } catch {
            print("[å½•éŸ³è°ƒè¯•] éŸ³é‡ç›‘æµ‹è®¾ç½®å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    // åœæ­¢éŸ³é‡ç›‘æµ‹
    func stopVolumeMonitoring() {
        print("[å½•éŸ³è°ƒè¯•] åœæ­¢éŸ³é‡ç›‘æµ‹")
        isMonitoring = false
        volumeTimer?.invalidate()
        volumeTimer = nil
        silenceTimer?.invalidate()
        silenceTimer = nil
    }
    
    // å¤„ç†éŸ³é‡å˜åŒ–
    private func handleVolumeChange(_ volume: Float) {
        print("[å½•éŸ³è°ƒè¯•] å½“å‰éŸ³é‡: \(String(format: "%.4f", volume)), é˜ˆå€¼: \(volumeThreshold), æ˜¯å¦å½•éŸ³ä¸­: \(isRecording)")
        
        if volume > volumeThreshold {
            // æ£€æµ‹åˆ°å£°éŸ³ï¼Œå¼€å§‹å½•éŸ³
            if !isRecording {
                print("[å½•éŸ³è°ƒè¯•] âœ… æ£€æµ‹åˆ°å£°éŸ³è¶…è¿‡é˜ˆå€¼ï¼Œè‡ªåŠ¨å¼€å§‹å½•éŸ³")
                startRecording()
            } else {
                print("[å½•éŸ³è°ƒè¯•] ğŸ”„ ç»§ç»­å½•éŸ³ä¸­ï¼ŒéŸ³é‡: \(String(format: "%.4f", volume))")
            }
            
            // å–æ¶ˆé™éŸ³å®šæ—¶å™¨
            if silenceTimer != nil {
                print("[å½•éŸ³è°ƒè¯•] ğŸ”„ å–æ¶ˆé™éŸ³å®šæ—¶å™¨")
                silenceTimer?.invalidate()
                silenceTimer = nil
            }
            
        } else {
            // æ£€æµ‹åˆ°é™éŸ³
            if isRecording && silenceTimer == nil {
                print("[å½•éŸ³è°ƒè¯•] ğŸ”‡ æ£€æµ‹åˆ°é™éŸ³ï¼Œå¼€å§‹3ç§’å€’è®¡æ—¶")
                
                // å¼€å§‹3ç§’é™éŸ³å€’è®¡æ—¶
                silenceTimer = Timer.scheduledTimer(withTimeInterval: silenceDetectionTime, repeats: false) { _ in
                    DispatchQueue.main.async {
                        print("[å½•éŸ³è°ƒè¯•] â° é™éŸ³3ç§’ï¼Œè‡ªåŠ¨åœæ­¢å½•éŸ³")
                        self.stopRecording()
                    }
                }
            }
        }
    }
    
    // å°†åˆ†è´å€¼è½¬æ¢ä¸ºéŸ³é‡å€¼
    private func convertPowerToVolume(_ power: Float) -> Float {
        // è°ƒæ•´åˆ†è´èŒƒå›´ï¼Œä½¿å…¶æ›´æ•æ„Ÿ
        let minDb: Float = -60.0  // æé«˜æœ€å°åˆ†è´å€¼
        let maxDb: Float = 0.0
        
        if power < minDb {
            return 0.0
        } else if power >= maxDb {
            return 1.0
        } else {
            let normalizedValue = (power - minDb) / (maxDb - minDb)
            // ä½¿ç”¨å¹³æ–¹æ ¹å‡½æ•°ä½¿ä½éŸ³é‡æ›´æ•æ„Ÿ
            return sqrt(normalizedValue)
        }
    }
    
    func startRecording() {
        guard !isRecording else { return }
        
        print("[å½•éŸ³è°ƒè¯•] å°è¯•å¼€å§‹å½•éŸ³")
        
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        let timestamp = DateFormatter().string(from: Date())
        recordingURL = documentsPath.appendingPathComponent("recording_\(timestamp).m4a")
        
        let settings = [
            AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
            AVSampleRateKey: 44100,
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]
        
        do {
            audioRecorder = try AVAudioRecorder(url: recordingURL!, settings: settings)
            audioRecorder?.delegate = self
            audioRecorder?.isMeteringEnabled = true
            audioRecorder?.prepareToRecord()
            
            let success = audioRecorder?.record() ?? false
            if success {
                DispatchQueue.main.async {
                    self.isRecording = true
                    print("[å½•éŸ³è°ƒè¯•] å½•éŸ³å¼€å§‹æˆåŠŸï¼Œæ–‡ä»¶è·¯å¾„: \(self.recordingURL?.path ?? "æœªçŸ¥")")
                }
            } else {
                print("[å½•éŸ³è°ƒè¯•] å½•éŸ³å¼€å§‹å¤±è´¥")
            }
        } catch {
            print("[å½•éŸ³è°ƒè¯•] å½•éŸ³è®¾ç½®å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    func stopRecording() {
        guard isRecording else { return }
        
        print("[å½•éŸ³è°ƒè¯•] åœæ­¢å½•éŸ³")
        audioRecorder?.stop()
        
        DispatchQueue.main.async {
            self.isRecording = false
        }
        
        // å–æ¶ˆé™éŸ³å®šæ—¶å™¨
        silenceTimer?.invalidate()
        silenceTimer = nil
        
        // ä¸Šä¼ å½•éŸ³æ–‡ä»¶
        if let url = recordingURL {
            uploadRecording(url: url)
        }
    }
    
    private func uploadRecording(url: URL) {
        print("[å½•éŸ³è°ƒè¯•] å¼€å§‹ä¸Šä¼ å½•éŸ³æ–‡ä»¶: \(url.path)")
        
        guard let audioData = try? Data(contentsOf: url) else {
            print("[å½•éŸ³è°ƒè¯•] è¯»å–å½•éŸ³æ–‡ä»¶å¤±è´¥")
            return
        }
        
        print("[å½•éŸ³è°ƒè¯•] å½•éŸ³æ–‡ä»¶å¤§å°: \(audioData.count) å­—èŠ‚")
        
        guard let uploadURL = URL(string: "https://emohunter-api-6106408799.us-central1.run.app/speech_to_text") else {
            print("[å½•éŸ³è°ƒè¯•] API URL æ— æ•ˆ")
            return
        }
        
        var request = URLRequest(url: uploadURL)
        request.httpMethod = "POST"
        
        let boundary = UUID().uuidString
        request.setValue("multipart/form-data; boundary=\(boundary)", forHTTPHeaderField: "Content-Type")
        
        var body = Data()
        body.append("--\(boundary)\r\n".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"audio\"; filename=\"recording.m4a\"\r\n".data(using: .utf8)!)
        body.append("Content-Type: audio/mp4\r\n\r\n".data(using: .utf8)!)
        body.append(audioData)
        body.append("\r\n--\(boundary)--\r\n".data(using: .utf8)!)
        
        request.httpBody = body
        
        URLSession.shared.dataTask(with: request) { data, response, error in
            DispatchQueue.main.async {
                if let error = error {
                    print("[å½•éŸ³è°ƒè¯•] ä¸Šä¼ å¤±è´¥: \(error.localizedDescription)")
                } else if let httpResponse = response as? HTTPURLResponse {
                    print("[å½•éŸ³è°ƒè¯•] ä¸Šä¼ å“åº”çŠ¶æ€ç : \(httpResponse.statusCode)")
                    if let data = data, let responseString = String(data: data, encoding: .utf8) {
                        print("[å½•éŸ³è°ƒè¯•] æœåŠ¡å™¨å“åº”: \(responseString)")
                    }
                }
            }
        }.resume()
    }
    
    deinit {
        stopVolumeMonitoring()
        if isRecording {
            stopRecording()
        }
    }
}

extension AudioRecordingManager: AVAudioRecorderDelegate {
    func audioRecorderDidFinishRecording(_ recorder: AVAudioRecorder, successfully flag: Bool) {
        print("[å½•éŸ³è°ƒè¯•] å½•éŸ³å®Œæˆï¼ŒæˆåŠŸ: \(flag)")
        if flag {
            print("[å½•éŸ³è°ƒè¯•] å½•éŸ³æ–‡ä»¶ä¿å­˜æˆåŠŸ")
        } else {
            print("[å½•éŸ³è°ƒè¯•] å½•éŸ³æ–‡ä»¶ä¿å­˜å¤±è´¥")
        }
    }
    
    func audioRecorderEncodeErrorDidOccur(_ recorder: AVAudioRecorder, error: Error?) {
        print("[å½•éŸ³è°ƒè¯•] å½•éŸ³ç¼–ç é”™è¯¯: \(error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")")
    }
}

struct CallView: View {
    @ObservedObject var callManager: CallManager
    @StateObject private var audioRecorder = AudioRecordingManager()
    @State private var isVideoEnabled = true
    @State private var isFrontCamera = true
    
    var body: some View {
        ZStack {
            // èƒŒæ™¯
            if callManager.callState == .connected && isVideoEnabled {
                // è§†é¢‘é€šè¯èƒŒæ™¯
                remoteView()
                    .ignoresSafeArea()
            } else {
                // éŸ³é¢‘é€šè¯èƒŒæ™¯
                LinearGradient(
                    gradient: Gradient(colors: [
                        Color(red: 0.98, green: 0.75, blue: 0.65),
                        Color(red: 0.99, green: 0.85, blue: 0.55)
                    ]),
                    startPoint: .topLeading,
                    endPoint: .bottomTrailing
                )
                .ignoresSafeArea()
            }
            
            VStack(spacing: 40) {
                Spacer()
                
                if callManager.callState != .connected || !isVideoEnabled {
                    // è”ç³»äººå¤´åƒå’ŒåŠ¨ç”»
                    Circle()
                        .fill(Color.clear)
                        .frame(width: 150, height: 150)
                        .overlay(
                            AdvancedGradientRippleAnimation(
                                color: .white,
                                maxSize: 180,
                                centerColor: Color.white,
                                edgeColor: .clear
                            )
                            .frame(width: 300, height: 300)
                        )
                }
                
                // è”ç³»äººå§“å
                Text(callManager.contactName)
                    .font(.largeTitle)
                    .fontWeight(.medium)
                    .foregroundColor(.white)
                    .shadow(color: .black.opacity(0.5), radius: 2)
                
                // é€šè¯çŠ¶æ€æ–‡æœ¬
                Text(statusText)
                    .font(.title3)
                    .foregroundColor(.white.opacity(0.8))
                    .shadow(color: .black.opacity(0.5), radius: 2)
                
              
                Spacer()
                
                // é€šè¯æ§åˆ¶æŒ‰é’®
                HStack(spacing: 40) {
                    if callManager.callState == .ringing {
                        // æ¥å¬æŒ‰é’®
                        Button(action: {
                            print("[å½•éŸ³è°ƒè¯•] æ¥å¬æŒ‰é’®è¢«ç‚¹å‡»")
                            callManager.answerCall()
                        }) {
                            Circle()
                                .fill(Color.green)
                            // å°†æ‰€æœ‰æŒ‰é’®æ”¹ä¸ºç»Ÿä¸€çš„ 65x65
                            .frame(width: 65, height: 65)
                                .overlay(
                                    Image(systemName: "phone.fill")
                                        .font(.system(size: 30))
                                        .foregroundColor(.white)
                                )
                        }
                    }
                    
                    if callManager.callState == .connected {
                        // ç§»é™¤å½•éŸ³æŒ‰é’®ï¼Œä¿ç•™å…¶ä»–åŠŸèƒ½æŒ‰é’®
                        
                        // è§†é¢‘å¼€å…³æŒ‰é’®
                        Button(action: {
                            print("[å½•éŸ³è°ƒè¯•] è§†é¢‘å¼€å…³æŒ‰é’®è¢«ç‚¹å‡»")
                            isVideoEnabled.toggle()
                        }) {
                            Circle()
                                .fill(isVideoEnabled ? Color.blue : Color.gray.opacity(0.3))
                                .frame(width: 65, height: 65)
                                .overlay(
                                    Image(systemName: isVideoEnabled ? "video.fill" : "video.slash.fill")
                                        .font(.system(size: 24))
                                        .foregroundColor(.white)
                                )
                        }
                        
                        // æ‘„åƒå¤´åˆ‡æ¢æŒ‰é’®ï¼ˆä»…åœ¨è§†é¢‘å¼€å¯æ—¶æ˜¾ç¤ºï¼‰
                        if isVideoEnabled {
                            Button(action: {
                                print("[å½•éŸ³è°ƒè¯•] æ‘„åƒå¤´åˆ‡æ¢æŒ‰é’®è¢«ç‚¹å‡»")
                                isFrontCamera.toggle()
                            }) {
                                Circle()
                                    .fill(Color.gray.opacity(0.3))
                                // å°†æ‰€æœ‰æŒ‰é’®æ”¹ä¸ºç»Ÿä¸€çš„ 65x65
                                .frame(width: 65, height: 65)
                                    .overlay(
                                        Image(systemName: "camera.rotate.fill")
                                            .font(.system(size: 24))
                                            .foregroundColor(.white)
                                    )
                            }
                        }
                        
                        // é™éŸ³æŒ‰é’®
                        Button(action: {
                            print("[å½•éŸ³è°ƒè¯•] é™éŸ³æŒ‰é’®è¢«ç‚¹å‡»")
                            // é™éŸ³åŠŸèƒ½å®ç°
                        }) {
                            Circle()
                                .fill(Color.gray.opacity(0.3))
                            // å°†æ‰€æœ‰æŒ‰é’®æ”¹ä¸ºç»Ÿä¸€çš„ 65x65
                            .frame(width: 65, height: 65)
                                .overlay(
                                    Image(systemName: "speaker.wave.2.fill")
                                        .font(.system(size: 24))
                                        .foregroundColor(.white)
                                )
                        }
                    }
                    
                    // æŒ‚æ–­æŒ‰é’®
                    Button(action: {
                        print("[å½•éŸ³è°ƒè¯•] æŒ‚æ–­æŒ‰é’®è¢«ç‚¹å‡»")
                        if audioRecorder.isRecording {
                            print("[å½•éŸ³è°ƒè¯•] æŒ‚æ–­æ—¶åœæ­¢å½•éŸ³")
                            audioRecorder.stopRecording()
                        }
                        callManager.endCall()
                    }) {
                        Circle()
                            .fill(Color.red)
                        // å°†æ‰€æœ‰æŒ‰é’®æ”¹ä¸ºç»Ÿä¸€çš„ 65x65
                        .frame(width: 65, height: 65)
                            .overlay(
                                Image(systemName: "phone.down.fill")
                                    .font(.system(size: 30))
                                    .foregroundColor(.white)
                            )
                    }
                }
                .padding(.bottom, 50)
            }
            .padding()
            
            // æœ¬åœ°è§†é¢‘é¢„è§ˆçª—å£
            if callManager.callState == .connected && isVideoEnabled {
                HStack {
                    SimpleCameraView()
                        .frame(width: 120, height: 160)
                        .background(Color.black.opacity(0.1))
                        .cornerRadius(12)
                        .overlay(
                            RoundedRectangle(cornerRadius: 12)
                                .stroke(Color.white, lineWidth: 0.6)
                        )
                        .shadow(color: .black.opacity(0.5), radius: 10, x: 0, y: 5)
                        .padding(.horizontal,-190)
                        .padding(.top, -330)
                }
                .zIndex(1000) // ç¡®ä¿å°çª—å£åœ¨æœ€ä¸Šå±‚
            }
        }
        .onAppear {
            print("[å½•éŸ³è°ƒè¯•] CallView å‡ºç°")
        }
        .onDisappear {
            print("[å½•éŸ³è°ƒè¯•] CallView æ¶ˆå¤±")
            audioRecorder.stopVolumeMonitoring()
            if audioRecorder.isRecording {
                print("[å½•éŸ³è°ƒè¯•] è§†å›¾æ¶ˆå¤±æ—¶åœæ­¢å½•éŸ³")
                audioRecorder.stopRecording()
            }
        }
        .onChange(of: callManager.callState) { newState in
            print("[å½•éŸ³è°ƒè¯•] é€šè¯çŠ¶æ€å˜åŒ–: \(newState)")
            
            switch newState {
            case .connected:
                // å»¶è¿Ÿ2ç§’åå¼€å§‹éŸ³é‡ç›‘æµ‹ï¼Œç¡®ä¿é€šè¯éŸ³é¢‘ä¼šè¯ç¨³å®š
                DispatchQueue.main.asyncAfter(deadline: .now() + 2.0) {
                    print("[å½•éŸ³è°ƒè¯•] é€šè¯å·²è¿æ¥ï¼Œå»¶è¿Ÿå¼€å§‹éŸ³é‡ç›‘æµ‹")
                    audioRecorder.startVolumeMonitoring()
                }
                
            case .ended:
                print("[å½•éŸ³è°ƒè¯•] é€šè¯å·²ç»“æŸï¼Œåœæ­¢éŸ³é‡ç›‘æµ‹å’Œå½•éŸ³")
                audioRecorder.stopVolumeMonitoring()
                if audioRecorder.isRecording {
                    audioRecorder.stopRecording()
                }
                
            default:
                break
            }
        }
    }
    
    private var statusText: String {
        switch callManager.callState {
        case .idle:
            return "Everything is okayğŸ˜"
        case .ringing:
            return "You look lonely , I can fix that..."
        case .connected:
            return callManager.formatDuration(callManager.callDuration)
        case .ended:
            return "é€šè¯ç»“æŸ"
        }
    }
}

// è¿œç¨‹è§†é¢‘è§†å›¾
struct RemoteVideoView: UIViewRepresentable {
    func makeCoordinator() -> Coordinator {
        Coordinator()
    }
    
    func makeUIView(context: Context) -> UIView {
        let containerView = UIView()
        containerView.backgroundColor = .clear
        
        let hostingController = UIHostingController(rootView: remoteView())
        context.coordinator.hostingController = hostingController
        
        hostingController.view.backgroundColor = .clear
        hostingController.view.frame = containerView.bounds
        hostingController.view.autoresizingMask = [.flexibleWidth, .flexibleHeight]
        
        containerView.addSubview(hostingController.view)
        
        return containerView
    }
    
    func updateUIView(_ uiView: UIView, context: Context) {
        // å¯ä»¥é€šè¿‡coordinatoræ›´æ–°è§†å›¾
    }
    
    class Coordinator {
        var hostingController: UIHostingController<remoteView>?
    }
}

// æ”¹è¿›çš„æœ¬åœ°è§†é¢‘é¢„è§ˆ
struct LocalVideoPreview: UIViewRepresentable {
    @Binding var isFrontCamera: Bool
    
    func makeUIView(context: Context) -> UIView {
        let containerView = UIView()
        containerView.backgroundColor = .black
        containerView.layer.cornerRadius = 12
        containerView.clipsToBounds = true
        
        let hostingController = UIHostingController(rootView: SimpleCameraView())
        hostingController.view.backgroundColor = .clear
        hostingController.view.frame = containerView.bounds
        hostingController.view.autoresizingMask = [.flexibleWidth, .flexibleHeight]
        
        containerView.addSubview(hostingController.view)
        
        return containerView
    }
    
    func updateUIView(_ uiView: UIView, context: Context) {
        // ç¡®ä¿è§†å›¾å¤§å°æ­£ç¡®
        if let hostingView = uiView.subviews.first {
            hostingView.frame = uiView.bounds
        }
    }
}

#Preview {
    CallView(callManager: CallManager())
}
